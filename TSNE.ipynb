{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前置作業 Preliminary work\n",
    "##### 匯入相關模組與設定 Import related modules and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "from pybiomart import Server\n",
    "import pyarrow as pa\n",
    "import plotly.express as px\n",
    "\n",
    "print(f\" [i] Start analyzing, total 7 steps...\")\n",
    "print(f\" [i] Setting up...\")\n",
    "\n",
    "# 強制 Qt 在 Linux 環境下使用 X11\n",
    "os.environ[\"QT_QPA_PLATFORM\"] = \"xcb\"\n",
    "\n",
    "# 防止 NumPy 佔用過多記憶體\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# 固定隨機種子確保可重現性\n",
    "np.random.seed(42)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 連線到ensembl資料庫擷取基因資料，分批次讀取gct檔案 \n",
    "##### Connect to the ensembl database to retrieve gene data and read gct files in batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hgnc_protein_coding():\n",
    "    print(\" [i] Querying HGNC protein coding genes via pybiomart...\")\n",
    "    # 建立連線與資料集\n",
    "    server = Server(host='http://www.ensembl.org')\n",
    "    dataset = server.marts['ENSEMBL_MART_ENSEMBL'].datasets['hsapiens_gene_ensembl']\n",
    "\n",
    "    # 取得 Ensembl ID 與 HGNC Symbol\n",
    "    genes_df = dataset.query(attributes=['ensembl_gene_id', 'hgnc_symbol', 'gene_biotype'])\n",
    "\n",
    "    # 去除 HGNC Symbol 為空的資料\n",
    "    genes_df = genes_df.dropna(subset=['HGNC symbol'])\n",
    "\n",
    "    # 找出 FAU 與 UBA52 的列\n",
    "    extra_genes = genes_df[genes_df['HGNC symbol'].isin(['FAU', 'UBA52'])]\n",
    "\n",
    "    # 篩選 Ribosomal Protein（HGNC symbol 開頭為 RPL 或 RPS）\n",
    "    genes_df = genes_df[genes_df['HGNC symbol'].str.startswith(('RPL', 'RPS'), na=False)]\n",
    "    genes_df = genes_df[genes_df['Gene type'] == 'protein_coding']\n",
    "\n",
    "    # 將 FAU 與 UBA52 加入並去除重複列\n",
    "    genes_df = pd.concat([genes_df, extra_genes]).drop_duplicates()\n",
    "    \n",
    "    # 移除重複的 Ensembl ID，保留第一筆\n",
    "    genes_df = genes_df.drop_duplicates(subset=['HGNC symbol'], keep='first')\n",
    "    \n",
    "    unwanted_genes = [\"RPL17-C18orf32\", \"RPL36A-HNRNPH2\", \n",
    "                      \"RPS6KA1\", \"RPS6KA5\", \"RPS19BP1\", \"RPS6KL1\", \"RPS6KA4\", \"RPS6KA3\", \"RPS6KB2\", \"RPS6KA6\", \"RPS6KC1\", \"RPS10-NUDT3\", \"RPS6KA2\", \"RPS6KB1\"]\n",
    "    genes_df = genes_df[~genes_df['HGNC symbol'].isin(unwanted_genes)]\n",
    "    print(genes_df)\n",
    "    \n",
    "    # 回傳對應字典\n",
    "    return dict(zip(genes_df['Gene stable ID'], genes_df['HGNC symbol']))\n",
    "\n",
    "ensembl_to_symbol = load_hgnc_protein_coding()\n",
    "print(f\" [i] Ribosomal Protein gene count: {len(ensembl_to_symbol)}\")\n",
    "\n",
    "def load_gct(filepath):\n",
    "    \"\"\"\n",
    "    逐行解析 GCT 檔案，確保數據格式一致，避免記憶體使用過高。\n",
    "    \"\"\"\n",
    "    print(\" [1] Detecting column names...\")\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    header_line = lines[2]  # `.gct` 的標題通常在第 3 行（index 2）\n",
    "    column_names = header_line.strip().split(\"\\t\")\n",
    "    gene_id_column = column_names[0]\n",
    "    print(f\" [2] Detected Gene_ID column: {gene_id_column}\")\n",
    "\n",
    "    print(\" [3] Streaming GCT data...\", end = \"\\n\")\n",
    "    print(\" [i] This may take a few minutes, please wait...\", end = \"\\n\")\n",
    "    filtered_data = []\n",
    "    \n",
    "    def process_chunk(chunk):\n",
    "        chunk = chunk.rename(columns={gene_id_column: \"Gene_ID\"})\n",
    "        chunk[\"Gene_ID\"] = chunk[\"Gene_ID\"].astype(str)\n",
    "        chunk.set_index(\"Gene_ID\", inplace=True)\n",
    "\n",
    "        # 🔹 確保基因 ID 的格式與 ensembl_to_symbol 一致（去掉 .X 後綴）\n",
    "        chunk.index = chunk.index.str.split('.').str[0]\n",
    "        \n",
    "        # 🔹 過濾我們要的 Ensembl ID\n",
    "        if chunk.index is None or chunk.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        return chunk[chunk.index.isin(ensembl_to_symbol)]\n",
    "\n",
    "    chunk_size = 1000\n",
    "    with pd.read_csv(filepath, sep=\"\\t\", skiprows=2, chunksize=chunk_size) as reader:\n",
    "        for chunk in reader:\n",
    "            processed_chunk = process_chunk(chunk)\n",
    "            if not processed_chunk.empty:\n",
    "                filtered_data.append(pa.Table.from_pandas(processed_chunk))\n",
    "\n",
    "    print(\" [4] Merging processed data...\")\n",
    "    final_table = pa.concat_tables(filtered_data).to_pandas()\n",
    "    if \"Description\" in final_table.columns:\n",
    "        final_table.drop(columns=[\"Description\"], inplace=True)\n",
    "    \n",
    "    # 轉置以符合橫向基因矩陣的格式\n",
    "    final_table = final_table.T\n",
    "    \n",
    "    # print(final_table.shape)\n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 讀取組織對應元資料\n",
    "##### Read metadata of corresponding tissues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata_labels(metadata_path, df, target_tissues=None):\n",
    "    print(f\" [i] Reading tissue metadata...\")\n",
    "    metadata_df = pd.read_csv(metadata_path, sep=\"\\t\", low_memory=False, usecols=[\"SAMPID\", \"SMTSD\"])\n",
    "    metadata_df = metadata_df[metadata_df[\"SAMPID\"].str.startswith(\"GTEX-\")]\n",
    "    metadata_df.set_index(\"SAMPID\", inplace=True)\n",
    "    metadata_filtered = metadata_df.loc[df]\n",
    "    metadata_filtered[\"GTEX_ID\"] = metadata_filtered.index.str.split(\"-\").str[:2].str.join(\"-\")\n",
    "    gtex_tissue_dict = metadata_filtered.set_index(\"GTEX_ID\")[\"SMTSD\"].to_dict()\n",
    "\n",
    "    sample_ids = df.str.split(\"-\").str[:2].str.join(\"-\")\n",
    "    tissue_labels = sample_ids.map(gtex_tissue_dict).dropna()\n",
    "\n",
    "    if target_tissues is not None:\n",
    "        tissue_labels = [label if label in target_tissues else \"Other\" for label in tissue_labels]\n",
    "    \n",
    "\n",
    "    return tissue_labels, metadata_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將元資料中多餘的資料截除，只留下有匹配的樣本資訊\n",
    "##### Remove redundant data from the metadata, leaving only matching sample information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_samples(df_gct, df_metadata, tissue_column=\"SMTSD\"):\n",
    "    gct_sample_ids = df_gct.columns.astype(str)\n",
    "    metadata_sample_ids = df_metadata.index.astype(str)\n",
    "\n",
    "    # 找出交集\n",
    "    common_samples = list(set(gct_sample_ids) & set(metadata_sample_ids))\n",
    "\n",
    "    print(f\" [i] GCT 樣本數：{len(gct_sample_ids)}\")\n",
    "    print(f\" [i] Metadata 樣本數：{len(metadata_sample_ids)}\")\n",
    "    print(f\" [i] GCT 與 Metadata 交集樣本數：{len(common_samples)}\")\n",
    "\n",
    "    # 過濾 GCT 以及 Metadata\n",
    "    filtered_df = df_gct[common_samples]\n",
    "    filtered_metadata = df_metadata.loc[common_samples].copy()\n",
    "\n",
    "    print(f\" [i] 可用的組織種類數（{tissue_column}）：{filtered_metadata[tissue_column].nunique()}\")\n",
    "    print(f\" [i] 可用組織列表：\\n{filtered_metadata[tissue_column].value_counts().sort_values(ascending=False)}\")\n",
    "\n",
    "    return filtered_df, filtered_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將gct檔案樣本資訊與元資料對齊\n",
    "##### Align gct file sample information with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_metadata_and_gct(filtered_df, filtered_metadata):\n",
    "    filtered_df = filtered_df\n",
    "    filtered_metadata = filtered_metadata\n",
    "    \n",
    "    # 對齊：只保留 metadata 中 index 有出現在 gct_df.columns 裡的樣本\n",
    "    metadata_matched = filtered_metadata.loc[filtered_metadata.index.intersection(filtered_df.columns)]\n",
    "\n",
    "    # 再反過來，從 gct_df 裡面挑出這些樣本（欄位）\n",
    "    gct_matched = filtered_df.loc[:, metadata_matched.index]\n",
    "\n",
    "    # 最後確認兩者是否一一對齊（順序一致）\n",
    "    print(\" [!] 是否完全對齊？\", all(metadata_matched.index == gct_matched.columns))\n",
    "    print(\" [!] 樣本數：\", len(metadata_matched))\n",
    "    \n",
    "    return gct_matched, metadata_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn預處理數據\n",
    "##### Preprocessing data using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    print(\" [5] Pre-processing data...\")\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df = df.select_dtypes(include=[np.number])  # 只保留數值欄位\n",
    "    data_scaled = scaler.fit_transform(df)\n",
    "    return data_scaled, data_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用t-SNE方法將資料降為二維\n",
    "##### Use t-SNE to reduce the data to two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE 降維\n",
    "def perform_tsne_np(data, perplexity = 30, learning_rate = 200, \n",
    "                    n_components=2, max_iter=2000, init = \"pca\", random_state=42):\n",
    "    print(\" [6] Performing t-SNE_NP...\")\n",
    "    from sklearn.manifold import TSNE\n",
    "    tsne = TSNE(n_components=n_components, perplexity=perplexity, \n",
    "                learning_rate=learning_rate, max_iter=max_iter, \n",
    "                init = init, random_state = random_state)\n",
    "    \n",
    "    return tsne.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用plotly繪製t-SNE散點圖，製作互動圖、存檔\n",
    "##### Use plotly to draw t-SNE scatter plot, make interactive graph, and archive it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製 t-SNE 圖形\n",
    "def plot_tsne(tsne_results, tissue_labels, output_path):\n",
    "    print(\" [7] Drawing t-SNE plot...\")\n",
    "    import seaborn as sns\n",
    "    tissues = tissue_labels.unique()\n",
    "    palette = sns.color_palette(\"hls\", len(tissues))\n",
    "    custom_order = (sorted(set(tissues)))\n",
    "    color_map = {\n",
    "        tissue: f\"rgb({int(r*255)}, {int(g*255)}, {int(b*255)})\"\n",
    "        for tissue, (r, g, b) in zip(custom_order, palette)\n",
    "    }\n",
    "    fig = px.scatter(x = tsne_results[:, 0], y = tsne_results[:, 1], \n",
    "                     color = tissue_labels, color_discrete_map = color_map,\n",
    "                     hover_name = tissue_labels, \n",
    "               title = \"t-SNE visualization of GTEx Data\", template='plotly_white', \n",
    "               width = 2000, height = 1600, \n",
    "               labels = {\n",
    "                    'tSNE-1': 't-SNE dimension 1',\n",
    "                    'tSNE-2': 't-SNE dimension 2'\n",
    "               }\n",
    "            )\n",
    "    fig.update_layout(\n",
    "        legend_title_text=\"Tissues\",\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='left',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        margin=dict(t=50, b=50, l=50, r=50)  # 避免圖例或標題被裁切\n",
    "    )\n",
    "    fig.show() # 如果要顯示圖片則取消註解\n",
    "    fig.write_image(output_path)\n",
    "    print(f\" [i] t-SNE figure is saved as: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 主執行流程\n",
    "##### Main process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    gct_file = r\"/home/terry_0714/gct_data/GTEx_Analysis_2022-06-06_v10_RNASeQCv2.4.2_gene_tpm_non_lcm.gct\"\n",
    "    metadata_path = r\"/home/terry_0714/gct_data/GTEx_Analysis_v10_Annotations_SampleAttributesDS.tsv\"\n",
    "    output_dir = r\"/home/terry_0714/tsne_plot\"\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "    # 讀取 GCT 檔案\n",
    "    gct_df = load_gct(gct_file)\n",
    "    _, metadata_df = load_metadata_labels(metadata_path, gct_df.index)\n",
    "    filtered_df, filtered_metadata = get_matched_samples(gct_df.T, metadata_df)\n",
    "    \n",
    "    # 資料對齊\n",
    "    gct_matched, metadata_matched= align_metadata_and_gct(filtered_df, filtered_metadata)\n",
    "    input = gct_matched.T.values\n",
    "    label = metadata_matched[\"SMTSD\"]\n",
    "    \n",
    "    # 資料預處理\n",
    "    processed_data, shape = preprocess_data(gct_matched.T)\n",
    "    \n",
    "    # t-SNE 降維\n",
    "    tsne_results = perform_tsne_np(processed_data)\n",
    "            \n",
    "    # 作圖\n",
    "    output_image = os.path.join(output_dir, f\"tsne_plot_p_30_lr_200.png\")\n",
    "    plot_tsne(tsne_results, label, output_image)\n",
    "    \n",
    "    print(\" [i] t-SNE analysis is completed.\")\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = int(end - start)\n",
    "    hours = elapsed_time // 3600\n",
    "    minutes = elapsed_time % 3600 // 60\n",
    "    seconds = elapsed_time % 60\n",
    "\n",
    "    print(f\" [i] Time spent: {hours} hours, {minutes} minutes and {seconds} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
